# -*- coding: utf-8 -*-
"""
Created on Thu Dec 19 11:43:33 2024

@author: qbrosset
"""
import tensorflow as tf
import tensorflow_hub as hub
from fastapi import FastAPI
from pydantic import BaseModel
from joblib import load
import string
import re
import nltk
from nltk.stem import WordNetLemmatizer
import numpy as np

# Charger le mod√®le sauvegard√©
model = load("best_model.joblib")

# Initialiser l'application FastAPI
app = FastAPI()

# D√©finir la structure des donn√©es d'entr√©e
class TweetInput(BaseModel):
    tweet: str  # Le texte du tweet √† analyser

""" Preprocessing du tweet """

# Liste des √©motic√¥nes et sigles √† remplacer
emoticons = {
    ":)": "smile", ":-)": "smile", ":D": "laugh", ":-D": "laugh", ";D": "wink_smile", ";)": "wink", ":P": "playful", ";P": "playful_wink",
    ":-P": "playful", "XD": "laugh_hard", "xD": "laugh_hard", "=)": "happy_face", ":]": "happy_face", ":-]": "happy_face", ":3": "cute_smile", 
    "<3": "heart", "‚ù§Ô∏è": "heart", "üòä": "blush", "‚ò∫Ô∏è": "smile_blush", "üòÑ": "smile_big", "üòÅ": "grin", "üòÜ": "laugh_out_loud", "üòÇ": "tears_of_joy",
    ":(": "sad", ":-(": "sad", ":'(": "crying", ":'-(": "crying", ":/": "disappointed", ":-/": "disappointed", ":|": "neutral", ":-|": "neutral",
    ">:(": "angry", ">:-(": "angry", "D:": "shocked", "DX": "distressed", "D8": "distressed", "D;": "distressed", "D=": "horrified", ">:O": "surprised",
    ">:0": "surprised", "üòî": "pensive", "üò¢": "crying", "üò≠": "sob", "üò°": "angry", "üò†": "annoyed", "üòû": "disappointed", "üòü": "worried",
    "üòí": "unamused", ":|": "neutral", ":-|": "neutral", ":o": "surprised", ":-o": "surprised", ":O": "surprised_big", ":-O": "surprised_big",
    "o.O": "confused", "O.o": "confused", "-_-": "unimpressed", "-.-": "bored", ">_>": "skeptical", "<_<": "skeptical", "üòê": "neutral_face",
    "üòë": "expressionless", "ü§î": "thinking", "üò∂": "speechless", "üôÑ": "eyeroll", ":*": "kiss", ":-*": "kiss", ";*": "wink_kiss",
    "üòã": "savoring_food", "üòú": "playful_face", "üòù": "playful_tongue", "ü§™": "zany_face", "üòé": "cool", "üòá": "innocent", "ü•∞": "affection",
    "ü§ó": "hug", "üòè": "smirk", "üôÉ": "upside_down_face", "üò¥": "sleepy", "üòå": "relieved", "ü§§": "drooling"
}

# Liste des stopwords en anglais
stopW = nltk.corpus.stopwords.words("english")
ponctuation = set(string.punctuation)
mots_nuages = ["going", "got", "go", "twitter", "lol", "quot", "amp", "can't", "today", "gonna", "ca", "n't", "gon", "na", "think", "s"]
stopW.extend(ponctuation)
stopW.extend(mots_nuages)

# Fonction pour retirer les stopwords
def sup_stopwords(word_list, stopwords):
    return [word for word in word_list if word not in stopwords]

# Fonction pour v√©rifier si une cha√Æne est un nombre
def is_number(s):
    try:
        float(s)  # Si la conversion en float fonctionne, c'est un nombre
        return True
    except ValueError:
        return False

# Fonction pour retirer les nombres de listes
def sup_nombres(word_list):
    return [word for word in word_list if not (isinstance(word, (int, float)) or is_number(word))]

# Chargement du mod√®le USE
embed = hub.load("https://tfhub.dev/google/universal-sentence-encoder/4")

# Initialisation du lemmatiseur
lemmatizer = WordNetLemmatizer()

def preprocess_tweet(tweet, emoticons_dict):
    # Remplacement des √©motic√¥nes par leur signification
    for emoticon, meaning in emoticons_dict.items():
        tweet = re.sub(re.escape(emoticon), meaning, tweet)
    
    # Normalisation
    tweet = tweet.lower()
    
    # Suppression des urls et mentions
    tweet = re.sub(r"http\S+|www\S+|https\S+", "", tweet, flags=re.MULTILINE)
    tweet = re.sub(r"@\s?\w+", "", tweet)
    
    # Tokenisation
    tokens = nltk.word_tokenize(tweet)
    
    # Suppression des stopwords
    tokens = sup_stopwords(tokens, stopW)
    tokens = sup_nombres(tokens)
    
    # Lemmatisation
    tokens = [lemmatizer.lemmatize(token) for token in tokens]
    
    return tokens

def feature_USE_fct(sentences, b_size):
    batch_size = b_size
    features_list = []

    for step in range(0, len(sentences), batch_size):
        batch_sentences = sentences[step:step + batch_size]
        if not batch_sentences:
            break
        # G√©n√©ration des features pour le batch
        feats = embed(batch_sentences)  # Utilisation de USE sur le batch
        features_list.append(feats)

    # Concat√©nation finale de toutes les features
    features = np.vstack(features_list) if features_list else np.array([])

    return features

# Param√®tres USE
batch_size = 10

@app.post("/predict/")
def predict_sentiment(data: TweetInput):
    # Pr√©traitement du tweet (adapt√© selon le mod√®le utilis√©)
    processed_tweet = preprocess_tweet(data.tweet, emoticons)
    
    # Extraction des features avec USE
    features = feature_USE_fct(processed_tweet, batch_size)
    
    # Si aucune feature n'est g√©n√©r√©e, lever une exception
    if features.size == 0:
        raise ValueError("No features generated from the input.")
    
    # Faire une pr√©diction avec le mod√®le
    prediction = model.predict(features)
    prediction_proba = model.predict_proba(features)
    
    # D√©terminer le sentiment en fonction de la pr√©diction
    sentiment = "Positif" if prediction[0] == 1 else "N√©gatif"
    
    # Probabilit√© associ√©e √† la classe pr√©dite
    confiance = round(prediction_proba[0, prediction[0]] * 100, 2)
    confiance = confiance.astype(str)
    
    # Retourner le sentiment
    return {"tweet": data.tweet, "sentiment": sentiment, "confiance": f"{confiance}%"}
